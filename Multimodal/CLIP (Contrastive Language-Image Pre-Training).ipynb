{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Transferable Visual Models From Natural Language Supervision\n",
    "\n",
    "[2103.00020] Learning Transferable Visual Models From Natural Language Supervision (arxiv.org)\n",
    "https://arxiv.org/abs/2103.00020\n",
    "\n",
    "https://github.com/openai/CLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instroduction\n",
    "\n",
    "거대한 NLP모델들이 공개되며 이것들을 Fine-tuning과 Transfer-learning등 활용해 여러 분야에 적용하는 것이 매우 좋은 성능을 내고 있어 여러 분야에서 사용되고 있다.\n",
    "\n",
    "그렇다면, 이런 text 모델들을 vision분야와 연계에서 사용하려면 어떤 방법을 사용하면 될까?\n",
    "ViT나 CNN(ResNet, VggNet)등은 이미지 자체로만 학습시키면 좋은 성능을 내지만 text와 함께 입력하면 쉽게 학습 되기 힘들다.\n",
    "\n",
    "이런 vision-text모델에서 zero-shot learning 까지 가능한 CLIP 모델이 공개되어 이미지와 텍스트를 연결해 주면서 Vision 분야에서 여러 SOTA 모델의 기반이 되어주고 있고, 멀티모달 분야의 필수적인 기반이 되었다.\n",
    "\n",
    "\n",
    "## 접근 방식\n",
    "\n",
    "![image](https://github.com/openai/CLIP/raw/main/CLIP.png)\n",
    "\n",
    "CLIP은 처음에 Contrastive pre-training 과정을 거친다. 각각의 encoder를 거친 text, image 데이터에 대한 embedding의 유사도를 계산하여 이를 각각 계산하는 방식이다. **(1) Contrastive pre-training**을 보면 여기서 대각 행렬(text와 image의 의미가 일치하는 쌍)에 있는 값들이 유사도가 가장 크고, 나머지 대각 행렬이 아닌 곳(text와 image의 의미가 일치하지 않는 쌍)에 있는 값들은 유사도가 낮도록 loss function을 구성하여 학습이 진행된다.\n",
    "\n",
    "\n",
    "이후 **(2) create dataset calssifier from label text**과정을 보면 특정 데이터셋의 label에 해당하는 text를 사용해서 dataset classifier를 구축한다. 이 text들을 text encoder를 통과시켜 text에 대한 embedding을 생성한다. 이 임베딩은 각 레이블에 대한 벡터로 작용한다.\n",
    "\n",
    "\n",
    "그 다음 **(3) Use for zero-shot prediction**에서 새로운 이미지를 넣어주면 image encoder를 거쳐 벡터로 변화시키고, 위의 과정에서 나온 text embedding과 유사도를 계산해 가장 유사도가 높은 항목을 새로운 image에 대한 text label로 선정한다.\n",
    "\n",
    "\n",
    "여기서의 특징은 학습에 이용되지 않았던 image를 입력해도, label prediction이 이루어 질 수 있기 떄문에 Zero-shot learning이 가능하다.\n",
    "\n",
    "\n",
    "Zero-shot learning의 장점은\n",
    "\n",
    "1. 새로운 카테고리에 대한 유연성: 이전에 없던 카테고리나 클래스에 유연하게 모델이 작동할 수 있다.\n",
    "\n",
    "\n",
    "2. 데이터 구축과 labeling 비용 절감: 새로운 데이터에 대한 사전 학습이나 labeling없이도 모델을 사용할 수 있기 떄문에, 데이터 구축과정과 labeling에 드는 비용과 시간을 크게 줄일 수 있다.\n",
    "\n",
    "\n",
    "3. 범용성과 확장성: 위의 장점들과 같이 Zero-shot learning은 모델의 범용성과 확장성이 크기 때문에 학습된 모델을 다른 데이터셋에도 적용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
